{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN/kPG+jiMr+dmgk3ws2Arq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kWSTNkbz6zCG"},"outputs":[],"source":[]},{"cell_type":"code","source":["#EXPERIMENT 5 : Apply support vector machines (SVMs) and neural  networks for classification in recommender systems.\n","\n","import pandas as pd\n","import numpy as np\n","import csv\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, classification_report\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","import time\n","\n","# ------------------- Load dataset with error handling -------------------\n","def load_clean_csv(file_path):\n","    cleaned_lines = []\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        reader = csv.reader(file)\n","        for i, row in enumerate(reader):\n","            try:\n","                if len(row) < 5:  # Skip rows with too few columns\n","                    continue\n","                cleaned_lines.append(row)\n","            except Exception as e:\n","                print(f\"Skipping corrupted row {i}: {row}, Error: {e}\")\n","\n","    df = pd.DataFrame(cleaned_lines[1:], columns=cleaned_lines[0])  # First row as headers\n","    return df\n","\n","# Load dataset\n","try:\n","    df = load_clean_csv('movie_dataset.csv')\n","except Exception as e:\n","    print(f\"Error loading dataset: {e}\")\n","    exit()\n","\n","# ------------------- Convert numeric columns -------------------\n","numeric_cols = ['budget', 'popularity', 'runtime', 'vote_average', 'vote_count']\n","for col in numeric_cols:\n","    df[col] = pd.to_numeric(df[col], errors='coerce')\n","\n","# ------------------- Select relevant features -------------------\n","selected_features = ['budget', 'genres', 'popularity', 'runtime', 'vote_average', 'vote_count', 'original_language']\n","df = df[selected_features]\n","\n","# ------------------- Handle missing values -------------------\n","num_features = ['budget', 'popularity', 'runtime', 'vote_average', 'vote_count']\n","cat_features = ['genres', 'original_language']\n","\n","# Define preprocessing pipelines\n","num_pipeline = Pipeline([\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler())\n","])\n","\n","cat_pipeline = Pipeline([\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n","])\n","\n","preprocessor = ColumnTransformer([\n","    ('num', num_pipeline, num_features),\n","    ('cat', cat_pipeline, cat_features)\n","])\n","\n","# ------------------- Apply transformations -------------------\n","X = preprocessor.fit_transform(df)\n","\n","# ------------------- Generate labels -------------------\n","df.loc[:, 'label'] = (df['vote_average'] >= 7).astype(int)  # Binary classification\n","y = df['label']\n","\n","# ------------------- Split data -------------------\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# ------------------- Train SVM Model -------------------\n","svm_start = time.time()\n","svm_model = SVC(kernel='rbf', C=1, gamma='scale')\n","svm_model.fit(X_train, y_train)\n","svm_preds = svm_model.predict(X_test)\n","svm_end = time.time()\n","\n","print(\"SVM Classification Report:\")\n","print(classification_report(y_test, svm_preds))\n","print(f\"SVM Training & Prediction Time: {svm_end - svm_start:.2f} seconds\")\n","\n","# ------------------- Train Neural Network Model -------------------\n","input_dim = X_train.shape[1]\n","\n","# Define model\n","input_layer = Input(shape=(input_dim,))\n","x = Dense(128, activation='relu')(input_layer)\n","x = Dropout(0.3)(x)\n","x = Dense(64, activation='relu')(x)\n","x = Dropout(0.3)(x)\n","x = Dense(32, activation='relu')(x)\n","output_layer = Dense(1, activation='sigmoid')(x)\n","\n","nn_model = Model(inputs=input_layer, outputs=output_layer)\n","nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","nn_start = time.time()\n","nn_model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n","nn_end = time.time()\n","\n","# Evaluate Neural Network\n","nn_preds = (nn_model.predict(X_test) > 0.5).astype(int)\n","\n","print(\"Neural Network Classification Report:\")\n","print(classification_report(y_test, nn_preds))\n","print(f\"Neural Network Training & Prediction Time: {nn_end - nn_start:.2f} seconds\")\n","\n","# ------------------- Compare Performance -------------------\n","svm_accuracy = accuracy_score(y_test, svm_preds)\n","nn_accuracy = accuracy_score(y_test, nn_preds)\n","\n","print(\"\\nModel Performance Comparison\")\n","print(f\"SVM Accuracy: {svm_accuracy * 100:.2f}%\")\n","print(f\"Neural Network Accuracy: {nn_accuracy * 100:.2f}%\")\n","\n","if svm_accuracy > nn_accuracy:\n","    print(\"SVM performed better!\")\n","else:\n","    print(\"Neural Network performed better!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsoutdAjuzRr","executionInfo":{"status":"ok","timestamp":1746339120050,"user_tz":-330,"elapsed":14987,"user":{"displayName":"000 111","userId":"14195104500313090051"}},"outputId":"09425995-cfb1-4be7-b116-2f4dcbf4f2f7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["SVM Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98       764\n","           1       0.93      0.90      0.92       197\n","\n","    accuracy                           0.97       961\n","   macro avg       0.95      0.94      0.95       961\n","weighted avg       0.97      0.97      0.97       961\n","\n","SVM Training & Prediction Time: 0.22 seconds\n","Epoch 1/5\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8114 - loss: 0.4601 - val_accuracy: 0.9553 - val_loss: 0.1099\n","Epoch 2/5\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9706 - loss: 0.0874 - val_accuracy: 0.9792 - val_loss: 0.0643\n","Epoch 3/5\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9753 - loss: 0.0608 - val_accuracy: 0.9761 - val_loss: 0.0558\n","Epoch 4/5\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9847 - loss: 0.0381 - val_accuracy: 0.9750 - val_loss: 0.0613\n","Epoch 5/5\n","\u001b[1m121/121\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0385 - val_accuracy: 0.9688 - val_loss: 0.0712\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n","Neural Network Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.96      0.98       764\n","           1       0.87      0.99      0.93       197\n","\n","    accuracy                           0.97       961\n","   macro avg       0.93      0.98      0.95       961\n","weighted avg       0.97      0.97      0.97       961\n","\n","Neural Network Training & Prediction Time: 7.95 seconds\n","\n","Model Performance Comparison\n","SVM Accuracy: 96.57%\n","Neural Network Accuracy: 96.88%\n","Neural Network performed better!\n"]}]}]}